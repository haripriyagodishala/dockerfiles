FROM almalinux:9

#docker build -t username/imagename:version . --> Dockerfile is required in current folder
#docker tag imagename:version username/imagename:version
#docker login
#docker push username/imagename:version
#docker run -d -p 80:80 username/imagename:version
#docker exec -it username/imagename:version bash

FROM --> Should be the first instruction to refer base OS
RUN --> installing packages and configuring image. runs at build time
CMD --> Runs at container creation time, it keeps container running ["command-name", "params"]
LABEL --> adds metadata to the image, useful while filtering the images
EXPOSE --> informs about the ports opened by container, cant' really open the ports, just as a information to user
COPY --> copies the files from workspace to image
ADD --> 1. can download files directly from internet, can untar directly into image
ENV --> sets the env variables to the container

ENTRYPOINT -
systemctl start Docker -> Starts the Docker in server if it is already installed
usermod -aG docker ec2-user -> adding ec2-user to the docker group
exit and login again to see the changes that is if user added to docker group or not
docker ps -> shows the running containers
search Dockerfile reference to know about the all commands details

Create a folder ENTRYPOINT and dockerfile
In dockerfile -
FROM almalinux:9
CMD ["ping","google.com"]

GIT clone in gitbash and in server also
gitbash-> git add, commit, push 
server -> git pull

superputty -> cd entrypoint/
docker build -t entry:v1 .
docker run -d entry:va
docker ps
docker logs -f <container-id> => -f for follow
google.com runs infinite time
docker rm -f <container-id> => removing container
docker run -d entry:v1 ping yahoo.com
yahoo.com runs infinite time

CMD can be overriden at run time
In dockerfile -
FROM almalinux:9
#CMD ["ping","google.com"]
ENTRYPOINT ["ping","google.com"]

In gitbash -> git add, commit, push
in server -> git pull
rebuild -> docker build -t entry:v1 .
rerun -> docker run -d entry:v1
docker logs <cont-id>
pinged google.com runs infinite time
docker ps
remove the prev container -> docker rm -f <cont-id>
docker run -d entry:v1 ping yahoo.com
docker ps -a
docker ps -a --no-trunc
ping google.com ping yahoo.com
We can not override ENTRYPOINT like CMD
If we try to do, it will append to command in entrypoint

for better results and best practices 
CMD can provide arguments to entrypoint
so we can mention dafault args through CMD and we can override them at runtime


In dockerfile -
FROM almalinux:9
CMD ["google.com"] -> default arugment
ENTRYPOINT ["ping"] 

git push, pull in server
rebuild and run
docker logs cont-id -> google.com pinges
docker rm -f cont-id
docker run -d entry:v1 yahoo.com
docker logs -f cont-id
yahoo.com will replace google.com
docker run entry:v1 microsoft.com

build, run, execute
docker build -t user:v1 .
docker run -d -p 80:80 user:v1
docker exec -it cont-id bash
-it => interactive terminal
you will get root access here when you don't have user instruction in dockerfile. 
cat dockerfile

USER instruction -
FROM almalinux:9
RUN useradd expense
USER expense
CMD ["sleep","100"]

git push and pull
rebuild, run, execute

USER - foe security you should not run containers using root users, it must be normal user. Atleasr last instruction should be  USER user-name

WORKDIR - it works same like cd in linux or shell
create folder WORKDIR and dockerfile

FROM almalinux:9
RUN mkdir /tmp/docker/
#RUN cd /tmp/docker/
WORKDIR /tmp/docker/
RUN pwd
RUN echo "hello" > hello.txt
CMD ["sleep","100"]

git push, pull
cd workdir/
rebuild, run, execute
docker build -t workdir:v1 .
docker run -d workdir:v1
docker exec -it cont-id bash
cd /tmp/docker/ --if you run cd command
ll or ls -l
find / -iname "hello.txt"
cd / -> root folder
ls -l

WORKDIR -> It is used to set the current working directory inside docker image

ARG -
IT IS USED TO set the variables at build time only, not inside the container

create ARG folder and dockerfile
FROM alma
ARG course="devops" \
    duration="1week"
RUN echo "course:$course, duration:$duration"
CMD ["sleep","100"]
git push, pull and cd to ARG
rebuild, run, execute -> type env
after running build command check the console, you can find the arg values here
ARG vs ENV
ENV variables can be accessed in both image build time and in the container. ARG variables only accessed at the time of image creation
you can use arg before from in one special case, that is to supply version to the base image
arg instruction before from is only valid until from. It can not be accessed after from.

We can override env and arg variables
docker build -t arg:v1 --build-arg course:k8s .

ARG version
#FROM almalinux:${version}
#give version at console
FROM almalinux:${version:-9}
ARG course="devops" \
    duration="1week" \
RUN echo "course:$course, duration:$duration, version:$version"
sleep also

How to access arg values inside container ?
you can set arg value to env variable

ARG course="devops" \
    duration="1week"
ENV course=$course
ENV var-name=$var-name

ONBUILD -
create a folder onbuild -> build, run
image name onbuild
docker images
create test folder inside onbuild and add index.html file also

name the image name onbuild-test
FROM alma
RUN dnf install nginx -y
RUN rm -rf /usr/share/nginx/html/index.html
ONBUILD COPY index.html /usr/share/nginx/html/index.html
CMD ["nginx","-g","daemon off"]

index.html -> <h1>Image Created by onbuild base image</h1>

docker run -d -p 8080:80 onbuild-test:v1 

copy the ip and see the result in web
onbuild is used to trigger few instructions at build when a user is using our image.
----------------------------------------------------------
EXPENSE-PROJECT
Create Expense-docker repo in github
Create mysql folder inside expense-docker folder
Create dockerfile inside mysql folder

2 ways
1. taking one base OS like almalinux:9 and then installing mysql server --> no use of docker here
2. Directly taking mysql server official Image

We no need to worry about the underlying base os image which is using in official images from docker hub
Our only aim is to deploy and run the application without any errors/lags

we use mysql8.0 version
FROM mysql:8.0
#setting root password for mysql server
ENV MYSQL_ROOT_PASSWORD = ExpenseApp@1
#creating database in the time of container creation
    #MYSQL_DATABASE=transactions \
    #MYSQL_USER=expense \
    #MYSQL_PASSWORD=ExpenseApp@1
ADD  scripts/*.sql /docker-entrypoint-initdb.d

create schema.sql file inside scripts folder which contains code about mysql database

In dockerhub search for official image of image you can find full documentation
backend->schema->backend.sql

git push, pull and cd to mysql
cat dockerfile

build -> docker build -t mysql:v1 .
run, execute -> mysql-u root -pExpenseApp@1
show databases;
use transactions;
show tables;
--------------------------------
Create an instance - docker take storage as 50 gb
open concepts git topic and open resize EBS storage

Write a shell script to install docker in archive folder

open superputty and run sudo su -
vim install docker-install.sh -> copy paste the script here and enter :wq!
sh install-docker.sh
exit and relogin
docker ps
dh -hT -> memory details
sudo su -
run commands which are there in resize file
lsblk
sudo growpart
sudo lvextend
goto ec2-user
-------------------------
Docker network
every vm get access to internet from aws ISP
docker0: is a virtual n/w interface. It acts as modem to
the containers in vm

git clone repo link
cd to mysql
build, run
docker ps
ifconfig
docker ps
docker inspect
 expense-documentation/backend.md
download the code in local machine and extract all
dockerfile in backend
 search for official image of node in docker reference
 in dockerfile -
FROM node:20
EXPOSE 8080 #just gives information
RUN mkdir /opt/server
WORKDIR /opt/server
COPY package.json .
COPY *.js .
RUN npm install
CMD ["node","index.js"]
#ENV DB_HOST="mysql"
ENV DB_HOST="local host"
docker run -d --name mysql mysql:v1

git push, pull, cd to respective folder
build, docker images, run by giving name backend
docker logs cont-id
you will get error
bcoz when docker uses default/bridge network, it can not communicate between the containers
you have to create your own bridge network called expense
docker network create expense
docker network ls
ifconfig
docker network connect expense mysql
docker inspect mysql

docker build
docker network ls
docker run -d --network expense/host --name mysql mysql:v1
docker run -d --network expense/host --name backend backend:v1
netstat -lntp
docker ps
sudo netstat -lntp
docker inspect mysql
no ip address for mysql

docker ps
docker logs backend
docker exec -it backend bash
telnet will not be there
Install telnet
to know os -> cat /etc/release
install telnet in docker debian -> search in web
RUN apt update && apt install telnet
telnet mysql 3306 -> check for connection
apt remove telnet -y

-----------------------------------------
frontend
create a frontend folder
download frontend code in expense documentation folder
download and extract all

create a code folder inside of frontend and move all files code into this
In dockerfile
FROM nginx
COPY code /usr/share/nginx/html
RUN rm -rf /etc/nginx/nginx.conf
RUN rm -rf /etc/nginx/conf.d/default.conf
COPY nginx.conf /etc/nginx/nginx.conf
#COPY expense.conf /etc/nginx/conf.d/expense.conf

git push, pull, cd to frontend folder
docker build -t frontend:v1 .
docker ps
run command with exposing port
docker run -d -p 80:80 --network expense --name frontend frontend:v1
docker exec -it frontend bash
cd /usr/share/nginx/html/
ls -l
cd /etc/nginx/
Copy paste expense.conf data from github to vs code
replace localhost with backend

host:
containers using host n/w will not get IP address means containers are sharing host IP address
Containers open host port
mysql -> 3306 -> host port
backend -> 8080 -> hostport
frontend -> 80 -> host port

nginx.conf -> backend with localhost
